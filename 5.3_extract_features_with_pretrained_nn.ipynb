{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "747578d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import joblib\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import vgg16\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e91f93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each time you add an image to images list, add 1 if image is dog and 0 if not dog, to labels list\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These images are 64x64 from imagenet database. Total of 64 images between 'dogs' and 'not-dogs'.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "699721f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dogs, add 1 as label and for non-dog, add 0\n",
    "\n",
    "#load all not dog images :\n",
    "for img in glob.glob('training_data/not_dogs/*.png'):\n",
    "    \n",
    "    img = image.load_img(img) #load image\n",
    "    img_array = image.img_to_array(img) #convert image to numpy array\n",
    "    images.append(img_array)#add image to list of images\n",
    "    \n",
    "    labels.append(0) #add 0 for each non dog image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4320fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all dog images :\n",
    "for img in glob.glob('training_data/dogs/*.png'):\n",
    "    \n",
    "    img = image.load_img(img) #load image\n",
    "    img_array = image.img_to_array(img) #convert image to numpy array\n",
    "    images.append(img_array)#add image to list of images\n",
    "    \n",
    "    labels.append(1) #add 1 for each non dog image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create training data :\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cbdd3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a numpy array with all images we loaded as this is what keras expect, not a list\n",
    "x_train = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f1105b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a numpy array with all labels we loaded as this is what keras expect\n",
    "y_train = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1297acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize image data to a 0-1 range\n",
    "#vgg model is trained on imagenet dataset\n",
    "\n",
    "x_train_norm = vgg16.preprocess_input(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9563d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a neural network :\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9d52e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "58900480/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#load a pre-trained nn to use as a feature extractor\n",
    "#remove the last layer (include_top = False) as we are using this model just for feature extraction.\n",
    "#In keras, top layer is the last layer in NN\n",
    "#shape of input image in training data , 64x64 with 3 color channels - red,green,blue. we are taking small size\n",
    "#as we want a faster training time. \n",
    "                           \n",
    "    \n",
    "pretrained_nn = vgg16.VGG16(weights = 'imagenet', include_top = False, input_shape=(64,64,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbb552ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed all images through NN and capture result : extract features for each image (in one pass)\n",
    "features_x = pretrained_nn.predict(x_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a27abf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_train.dat']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save features to a file :\n",
    "joblib.dump(features_x,'x_train.dat') #features\n",
    "joblib.dump(y_train,'y_train.dat') #labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b95f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
