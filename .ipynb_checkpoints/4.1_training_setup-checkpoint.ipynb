{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e724810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f634575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4159ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise dataset to a range between 0 and 1\n",
    "X_train_re = X_train.astype('float32')/255\n",
    "X_test_re = X_test.astype('float32')/255\n",
    "\n",
    "y_train_cat = to_categorical(y_train, 10) # num_classes = 10\n",
    "y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fde4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding = 'same', activation = 'relu',input_shape = (32,32,3))) \n",
    "model.add(Conv2D(32, (3,3),activation = 'relu')) #padding not needed\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) #size of area we want to pool together, pool size = 2 x 2 pixels\n",
    "model.add(Dropout(.25)) #% of random connections to cut, usually a val between 25% - 50% works well\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding = 'same', activation = 'relu')) \n",
    "model.add(Conv2D(64, (3,3), activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size = (2,2))) #size of area we want to pool together, pool size = 2 x 2 pixels\n",
    "model.add(Dropout(.25))  \n",
    "\n",
    "model.add(Flatten())\n",
    "                 \n",
    "model.add(Dense(512,activation = 'relu')) #\n",
    "model.add(Dropout(.50)) #the NN will try harder to learn\n",
    "\n",
    "model.add(Dense(10,activation = 'softmax')) #we need 10 nodes as we have 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f1968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complie NN : create a NN in  memory, also how will be measure its accuracy\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "batch size = number of images we want to feed the NN at once. If number is too low, training might take a long time \n",
    "and never finish. If number is too high, we might run out of memory on our computer.\n",
    "typical batch sizes are between 32 and 128 images.\n",
    "epoch : how many times do we want to go through our training data set. One full pass is called an epoch. More the epochs, \n",
    "more chance the NN to learn and longer it will take.\n",
    "Eventually , we will hit a point where doing additional training will not help.\n",
    "\n",
    "In general, larger the data set, less passes you will do on it. For eg : for a data set will millions of images, use 5\n",
    "epochs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e492cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/782 [==============================] - 18s 19ms/step - loss: 1.5322 - accuracy: 0.4385 - val_loss: 1.1687 - val_accuracy: 0.5810\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 1.1050 - accuracy: 0.6045 - val_loss: 0.9774 - val_accuracy: 0.6536\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.9375 - accuracy: 0.6696 - val_loss: 0.8518 - val_accuracy: 0.7026\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.8372 - accuracy: 0.7053 - val_loss: 0.7839 - val_accuracy: 0.7213\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 14s 19ms/step - loss: 0.7681 - accuracy: 0.7295 - val_loss: 0.7291 - val_accuracy: 0.7456\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 14s 19ms/step - loss: 0.7079 - accuracy: 0.7495 - val_loss: 0.7118 - val_accuracy: 0.7577\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.6641 - accuracy: 0.7651 - val_loss: 0.7078 - val_accuracy: 0.7553\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.6325 - accuracy: 0.7768 - val_loss: 0.6578 - val_accuracy: 0.7696\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 14s 19ms/step - loss: 0.5923 - accuracy: 0.7938 - val_loss: 0.6620 - val_accuracy: 0.7716\n",
      "Epoch 10/30\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.5646 - accuracy: 0.8024 - val_loss: 0.6508 - val_accuracy: 0.7786\n",
      "Epoch 11/30\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.5344 - accuracy: 0.8105 - val_loss: 0.6493 - val_accuracy: 0.7824\n",
      "Epoch 12/30\n",
      "782/782 [==============================] - 872s 1s/step - loss: 0.5166 - accuracy: 0.8175 - val_loss: 0.6348 - val_accuracy: 0.7850\n",
      "Epoch 13/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.4924 - accuracy: 0.8257 - val_loss: 0.6479 - val_accuracy: 0.7853\n",
      "Epoch 14/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.4770 - accuracy: 0.8307 - val_loss: 0.6289 - val_accuracy: 0.7900\n",
      "Epoch 15/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.4579 - accuracy: 0.8399 - val_loss: 0.6345 - val_accuracy: 0.7869\n",
      "Epoch 16/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.4400 - accuracy: 0.8447 - val_loss: 0.6255 - val_accuracy: 0.7887\n",
      "Epoch 17/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.4195 - accuracy: 0.8501 - val_loss: 0.6388 - val_accuracy: 0.7895\n",
      "Epoch 18/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.4106 - accuracy: 0.8551 - val_loss: 0.6337 - val_accuracy: 0.7886\n",
      "Epoch 19/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3914 - accuracy: 0.8606 - val_loss: 0.6526 - val_accuracy: 0.7945\n",
      "Epoch 20/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3884 - accuracy: 0.8610 - val_loss: 0.6401 - val_accuracy: 0.7919\n",
      "Epoch 21/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3685 - accuracy: 0.8698 - val_loss: 0.6337 - val_accuracy: 0.7967\n",
      "Epoch 22/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3614 - accuracy: 0.8703 - val_loss: 0.6366 - val_accuracy: 0.7968\n",
      "Epoch 23/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3526 - accuracy: 0.8745 - val_loss: 0.6699 - val_accuracy: 0.7907\n",
      "Epoch 24/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3416 - accuracy: 0.8805 - val_loss: 0.6438 - val_accuracy: 0.7944\n",
      "Epoch 25/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3371 - accuracy: 0.8794 - val_loss: 0.6328 - val_accuracy: 0.7975\n",
      "Epoch 26/30\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.3275 - accuracy: 0.8843 - val_loss: 0.6516 - val_accuracy: 0.7962\n",
      "Epoch 27/30\n",
      "782/782 [==============================] - 14s 19ms/step - loss: 0.3175 - accuracy: 0.8865 - val_loss: 0.6314 - val_accuracy: 0.7990\n",
      "Epoch 28/30\n",
      "782/782 [==============================] - 14s 19ms/step - loss: 0.3199 - accuracy: 0.8872 - val_loss: 0.6456 - val_accuracy: 0.7999\n",
      "Epoch 29/30\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.3089 - accuracy: 0.8899 - val_loss: 0.6697 - val_accuracy: 0.8021\n",
      "Epoch 30/30\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.3013 - accuracy: 0.8950 - val_loss: 0.6888 - val_accuracy: 0.7935\n",
      "Training time for CNN is 1298.4272818565369 seconds\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "t1 = time.time()\n",
    "model.fit(\n",
    "    X_train_re,\n",
    "    y_train_cat,\n",
    "    batch_size = 64, #typical size between 32 and 128\n",
    "    epochs = 30, # 1 full pass through training data is called an epoch\n",
    "    validation_data = (X_test_re,y_test_cat),\n",
    "    shuffle = True #mix order of training data as order of data should not influence training\n",
    ")\n",
    "t2 = time.time()\n",
    "print(f'Training time for CNN is {t2-t1} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f5eb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4383"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save NN structure : which layers got created and in which order they got hooked together\n",
    "model_structure = model.to_json()\n",
    "#write json data to a text file\n",
    "f = Path('model_structure.json')\n",
    "f.write_text(model_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e14a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save NN's trained weights : As NN is trained, weights at each node are adjusted to control how signals flow through NN.\n",
    "#by saving weights, we are saving how NN actually works\n",
    "\n",
    "model.save_weights('model_weights.h5') #h5 is binary format, used for saving large binary files efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "loss = how wrong the NN is right now. lower this number, better our NN is performing.this number should go down\n",
    "in training process.\n",
    "acc = current accuracy = how often NN is making correct prediction. this number should go up as training continues.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
